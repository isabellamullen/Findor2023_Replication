---
title: "replication_study3_alternatemodel"
output: pdf_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rio)
library(dplyr)
library(PerformanceAnalytics)
library(kableExtra)
library(psych)
library(ggplot2)
library(jmv)
library(magick)
library(report)
library(reshape2)
library(ordinal)
library(RVAideMemoire)
library(emmeans)
library(effectsize)
library(repmod)
library(MANOVA.RM)
library(ggrepel)
library(matrixTests)
library(tidyverse)
library(lessR)
library(rstatix)
library(multcomp)
library(jtools)
library(sjPlot)
library(generalhoslem)
library(effects)
library(lmtest)

#added
library(ggdist)



set.seed(42)

options(scipen=999, digits=3)

#This function concatenates multiple vectors element-wise while handling NA values by replacing them with empty strings.
#Works like paste(), but ensures that NA values are treated as missing (not "NA" as paste() would normally do).
#Removes unnecessary spaces or separators from the output.
#Converts empty results back to NA.

paste_na <- function(..., sep = " ") {
  L <- list(...)
  L <- lapply(
    L,
    function(x) {
      x[is.na(x)] <- ""
      x
    }
  )
  out <- gsub(
    paste0("(^", sep, "|", sep, "$)"), "",
    gsub(
      paste0(sep, sep), sep,
      do.call(paste, c(L, list(sep = sep)))
    )
  )
  is.na(out) <- out == ""
  return(out)
}


```
# Study 3 {.tabset}
## Data {.tabset}
### Data load
```{r}
s3 <- import("../original_materials/data/Study3.sav")
```

### Data prep
```{r, message=FALSE, results='hide'}
s3$group= factor(s3$SKUPINA, levels = c(1, 2,3,4), labels = c("Control","Equality", "Proportionality", "Need"))
s3$SEX <- factor(s3$SEX, levels = c(1, 2), labels = c("Male","Female"))
s3$AGECAT= factor(s3$AGECAT, levels = c(1,2,3,4,5,6), labels = c("18-24","25-34","35-44", "45-54","55-64","65+"))
s3$EDU= factor(s3$EDU, levels = c(1, 2,3,4), labels = c("Primary","Secondary (no diploma)","Secondary (complete)", "University"))
s3$SIZE= factor(s3$SIZE, levels = c(1, 2,3,4,5), labels = c("less than 1k","1k-4 999","5k-19 999", "20k - 99 999","100k+"))
s3$REG= factor(s3$REG, levels = c(1, 2,3,4,5,6,7,8), labels = c("Bratislavsky","Trnavsky","Trenciansky", "Nitriansky","Zilinsky","Banskobystricky","Presovsky","Kosicky"))


s3$income <- car::recode(s3$PINCOME,"'1'='below median';'2'='below median';'8'='NA';'9'='NA'; else = 'above median'")
```

```{r}
# Checking the data types of the dataset
str(s3)
```

### Original Model

```{r}
s3$E1 <- as.ordered(s3$E1)
s3$E2 <- as.ordered(s3$E2)
s3$E3 <- as.ordered(s3$E3)
s3$E4 <- as.ordered(s3$E4)

s3personal  <- polr(E3 ~ group, data = s3, Hess=TRUE)
summary(s3personal)
ctable <- coef(summary(s3personal))
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
(ctable <- cbind(ctable, "p value" = p))
ci <- confint(s3personal)
exp(cbind(OR = coef(s3personal), ci))
```

### Alternate Model

```{r}
# We present an alternate model with a changed linear predictor
s3personal_alter <- polr(E3 ~ group + AGE + EDU + SEX + REG ,
                         data = s3, Hess=TRUE)
summary(s3personal_alter)
ctable <- coef(summary(s3personal_alter))
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
(ctable <- cbind(ctable, "p value" = p))
ci <- confint(s3personal_alter)
exp(cbind(OR = coef(s3personal_alter), ci))
```

```{r}
# This test is an indicator of whether we have used an appropriate model to
# explain the data. The p-value > 0.05 confirms for us a good fit for our model.
print(lipsitz.test(s3personal))
print(lipsitz.test(s3personal_alter))
```

#### Confusion Tables

```{r}
# Original Model
predict_orig <-  predict(s3personal, s3)
cTab_orig <- table(s3$E3, predict_orig)
print(cTab_orig)

# Alternate Model
predict_alter <-  predict(s3personal_alter, s3)
cTab_alter <- table(s3$E3, predict_alter)
cTab_alter
```

#### (In-sample Performance) Confusion Matrix and Accuracy

```{r}
# Predicted classes
pred_logit <- predict(s3personal, type = "class")
pred_alter <- predict(s3personal_alter, type = "class")

# Confusion matrices
table(pred_logit, s3$E3)
table(pred_alter, s3$E3)

# Accuracy calculation
mean(pred_logit == factor(s3$E3, ordered = FALSE))
mean(pred_alter == factor(s3$E3, ordered = FALSE))
```

#### (In-sample Performance) ROC Curve

```{r}
library(pROC)

# Binary outcome 1: E3 = 1 vs Others
s3$E3_bin1 <- ifelse(s3$E3 == levels(s3$E3)[1], 1, 0)

# Binary outcome 2: E3 ≤ 2 vs E3 ≥ 3
s3$E3_bin2 <- ifelse(s3$E3 %in% levels(s3$E3)[1:2], 1, 0)

# Binary outcome 3: E3 ≤ 3 vs E3 = 4
s3$E3_bin3 <- ifelse(s3$E3 %in% levels(s3$E3)[1:3], 1, 0)

# Probabilities for each class
prob_logit <- predict(s3personal, data = s3, type = "prob")
prob_alter <- predict(s3personal_alter, data = s3, type = "prob")
```

```{r}
# ROC for predicting E3 = 1
roc_1_orig <- roc(s3$E3_bin1, prob_logit[, 1])

# ROC for predicting E3 ≤ 2
roc_2_orig <- roc(s3$E3_bin2, prob_logit[, 1] + prob_logit[, 2])

# ROC for predicting E3 ≤ 3
roc_3_orig <- roc(s3$E3_bin3, prob_logit[, 1] + prob_logit[, 2] +
                     prob_logit[, 3])

plot(roc_1_orig, col = "blue",
     main = "ROC Curves for Ordered Logistic Regression - Original Model")
plot(roc_2_orig, col = "red", add = TRUE)
plot(roc_3_orig, col = "green", add = TRUE)

legend("bottomright", 
       legend = c("E3 = 1", "E3 ≤ 2", "E3 ≤ 3"), 
       col = c("blue", "red", "green"), lwd = 2)
```


```{r}
# ROC for predicting E3 = 1
roc_1_alter <- roc(s3$E3_bin1, prob_alter[, 1])

# ROC for predicting E3 ≤ 2
roc_2_alter <- roc(s3$E3_bin2, prob_alter[, 1] + prob_alter[, 2])

# ROC for predicting E3 ≤ 3
roc_3_alter <- roc(s3$E3_bin3, prob_alter[, 1] + prob_alter[, 2] +
                     prob_alter[, 3])

plot(roc_1_alter, col = "blue",
     main = "ROC Curves for Ordered Logistic Regression - Alternate Model")
plot(roc_2_alter, col = "red", add = TRUE)
plot(roc_3_alter, col = "green", add = TRUE)

legend("bottomright", 
       legend = c("E3 = 1", "E3 ≤ 2", "E3 ≤ 3"), 
       col = c("blue", "red", "green"), lwd = 2)
```

#### (In-sample Performance) Log-likelihood Ratio Test, AIC and BIC

```{r}
s3personal$AIC <- round(AIC(s3personal), 1)
s3personal$BIC <- round(BIC(s3personal), 1)

s3personal_alter$AIC <- round(AIC(s3personal_alter), 1)
s3personal_alter$BIC <- round(BIC(s3personal_alter), 1)

# Perform the likelihood ratio test
lr_test <- lrtest(s3personal, s3personal_alter)

# Extract log-likelihood and p-value
logLik_value_orig <- as.numeric(logLik(s3personal))
logLik_value_alter <- as.numeric(logLik(s3personal_alter))
p_value <- lr_test$`Pr(>Chisq)`[2]  # Extract p-value from second row

stargazer::stargazer(s3personal, s3personal_alter, type = "text",
                     keep.stat=c("bic","aic", "n"),
                     add.lines = list(
                       c("Log-Likelihood", round(logLik_value_orig, 2),
                         paste0(round(logLik_value_alter, 2),
                                " (", signif(p_value, 3), ")"))
                       )
                     )
```

#### (In-sample Performance) Observed vs. Predicted Probability Plot

```{r}
library(ggplot2)
library(tidyr)
library(dplyr)  # For data wrangling

# Reshaping the Data to Long Format
calibration_data_long <- data.frame(
  Observed = as.factor(s3$E3),
  prob_logit_1 = prob_logit[,1],
  prob_logit_2 = prob_logit[,2],
  prob_logit_3 = prob_logit[,3],
  prob_logit = prob_logit[,4],
  prob_alter_1 = prob_alter[,1],
  prob_alter_2 = prob_alter[,2],
  prob_alter_3 = prob_alter[,3],
  prob_alter = prob_alter[,4]
) %>%
  pivot_longer(
    cols = -Observed,
    names_to = c("Model", "Category"),
    names_pattern = "prob_(logit|alter)_?(\\d*)",
    values_to = "Predicted_Probability"
  ) %>%
  mutate(Category = as.factor(Category))  # Ensure category is treated as a factor

# Plot
ggplot(calibration_data_long, aes(x = Observed, y = Predicted_Probability, color = Model)) +
  geom_point(position = position_jitter(width = 0.2, height = 0), alpha = 0.4) +
  geom_smooth(method = "loess", se = FALSE) +
  labs(title = "Multi-Category Calibration Plot",
       x = "Observed Outcome",
       y = "Predicted Probability") +
  scale_color_manual(values = c("logit" = "blue", "alter" = "red")) +
  theme_minimal()
```

#### (Out-of-sample Performance) K-fold Cross-Validation

```{r}
library(caret)

# Cross-validation control
ctrl <- trainControl(method = "cv", number = 10)

# Fit models with cross-validation
logit_cv <- train(E3 ~ group, data = s3, method = "polr", trControl = ctrl)
alter_cv <- train(E3 ~ group + AGE + SEX + EDU + REG, data = s3,
                   method = "polr", trControl = ctrl)

# Extract results
logit_results <- logit_cv$results
alter_results <- alter_cv$results

# Add final model details
logit_results$Final_Model <- logit_cv$finalModel$method
alter_results$Final_Model <- alter_cv$finalModel$method

# Format results for stargazer
logit_summary <- data.frame(
  Model = "Original",
  Method = logit_results$method,
  Accuracy = round(logit_results$Accuracy, 3),
  Kappa = round(logit_results$Kappa, 3),
  Final_Model = logit_cv$finalModel$method
)

alter_summary <- data.frame(
  Model = "Alternative",
  Method = alter_results$method,
  Accuracy = round(alter_results$Accuracy, 3),
  Kappa = round(alter_results$Kappa, 3),
  Final_Model = alter_cv$finalModel$method
)

# Combine results
cv_results <- rbind(logit_summary, alter_summary)

# Display using stargazer
library(stargazer)
stargazer(cv_results, summary = FALSE, title = "Cross-Validation Results",
          type = "text")
```

```{r}
# Compare resampling results
resamples <- resamples(list(general = alter_cv, restricted = logit_cv))
summary(resamples)
```
```{r}
bwplot(resamples)
```


#### (Independent Variable Effects)

```{r}
# This function gets the most often repeating factor value in a column
mode_fctr <- function(x) levels(x)[which.max(tabulate(match(x, levels(x))))]

# This function gets the most often repeating value in a column
mode_char <- function(x) unique(x)[which.max(tabulate(match(x, unique(x))))]

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```


```{r, fig.width=8, fig.height=6}
plot(Effect(focal.predictors = "AGE", s3personal_alter))
```

```{r, fig.width = 10}
plot(Effect(focal.predictors = "REG", s3personal_alter))
```

#### (Quantity of Interest)

```{r, fig.width=8, fig.height=5}

s3personal_alter <- polr(E3 ~ as.numeric(group) + AGE + as.numeric(EDU) +
                                 as.numeric(SEX) + as.numeric(REG), data = s3,
                               Hess=TRUE, method = "probit")

#We create a scenario where we look at the following for the Bratislavsky and
# Zilinsky regions
# Median AGE
# Most often repeating (mode) EDU
# Most often repeating (mode) SEX
# REG = 1/5 (Bratislavsky/Zilinsky)

X.low<-c(group = mode_char(as.numeric(filter(s3, REG == "Bratislavsky")$group)), 
         AGE = median(filter(s3, REG == "Bratislavsky")$AGE),
         EDU = mode_char(as.numeric(filter(s3, REG == "Bratislavsky")$EDU)),
         SEX = mode_char(as.numeric(filter(s3, REG == "Bratislavsky")$SEX)),
         REG = 1) #REG=Bratislavsky

X.high<-c(group = mode_char(as.numeric(filter(s3, REG == "Zilinsky")$group)),
        AGE = median(filter(s3, REG == "Zilinsky")$AGE),
        EDU = mode_char(as.numeric(filter(s3, REG == "Zilinsky")$EDU)),
        SEX = mode_char(as.numeric(filter(s3, REG == "Zilinsky")$SEX)),
        REG = 5) #REG=Zilinsky

draws<-mvrnorm(1000, #1000 draws;
               c(coef(s3personal_alter),
                 s3personal_alter$zeta), #note inclusion of cutpoints
               solve(s3personal_alter$Hessian))

B<-draws[,1:length(coef(s3personal_alter))]
Taus<-draws[,(length(coef(s3personal_alter))+1):ncol(draws)]

# Predicted probabilities for coop = 1 and coop = 4
pi.class1.sc1 <- plogis(Taus[, 1] - B %*% X.low) # Pr(Y = 1)
pi.class1.sc2 <- plogis(Taus[, 1] - B %*% X.high)

pi.class2.sc1 <- plogis(Taus[, 2] - B %*% X.low) -
  plogis(Taus[, 1] - B %*% X.low) # Pr(Y = 2)
pi.class2.sc2 <- plogis(Taus[, 2] - B %*% X.high) -
  plogis(Taus[, 1] - B %*% X.high)

pi.class3.sc1 <- plogis(Taus[, 3] - B %*% X.low) -
  plogis(Taus[, 2] - B %*% X.low) # Pr(Y = 3)
pi.class3.sc2 <- plogis(Taus[, 3] - B %*% X.high) -
  plogis(Taus[, 2] - B %*% X.high)

pi.class4.sc1 <- 1 - plogis(Taus[, 3] - B %*% X.low) # Pr(Y = 4)
pi.class4.sc2 <- 1 - plogis(Taus[, 3] - B %*% X.high)

# Computing difference in probabilities
fd.class1 <- pi.class1.sc2 - pi.class1.sc1
fd.class2 <- pi.class2.sc2 - pi.class2.sc1
fd.class3 <- pi.class3.sc2 - pi.class3.sc1
fd.class4 <- pi.class4.sc2 - pi.class4.sc1

plot(density(fd.class1, adjust = 1.5),
     xlim = c(-0.8, 0.8),
     ylim = range(density(fd.class1)$y, density(fd.class2)$y, 
                  density(fd.class3)$y, density(fd.class4)$y),
     xlab = "Change in Predicted Probability",
     col = "lightgreen", bty = "n",
     yaxt = "n", lwd = 2,
     main = "Implied effect on E3 (Personal Agreement of Construction of Apartment)",
     ylab = "",
     )

lines(density(fd.class2, adjust = 1.5), col = "lightblue", lwd = 2, lty = 2)
lines(density(fd.class3, adjust = 1.5), col = "lightpink", lwd = 2, lty = 3)
lines(density(fd.class4, adjust = 1.5), col = "lightgoldenrod", lwd = 2,
      lty = 4)

legend(
  "topleft",  # Adjust x and y to move the legend
  legend = c(
    "Pr(E3 = 1 | REG = Bratislavsky - REG = Zilinsky)",
    "Pr(E3 = 2 | REG = Bratislavsky - REG = Zilinsky)",
    "Pr(E3 = 3 | REG = Bratislavsky - REG = Zilinsky)",
    "Pr(E3 = 4 | REG = Bratislavsky - REG = Zilinsky)"
  ),
  col = c("lightgreen", "lightblue", "lightpink", "lightgoldenrod"),
  lwd = 2,
  bty = "n", cex = 0.6
)
```

